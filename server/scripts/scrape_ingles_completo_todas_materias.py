#!/usr/bin/env python3
"""
Script de Scraping Completo: InglÃ©s + Todas las Asignaturas Faltantes
Incluye: ING_PROP (1Â°-4Â°), ING (5Â°-6Â°), y todas las demÃ¡s asignaturas en todos los grados aplicables
VersiÃ³n: 1.3.0 - Completo y Correcto con InglÃ©s Dual
"""

import sys
import os
import subprocess
import time
import pandas as pd
from datetime import datetime

def log_info(message):
    """Logger simple"""
    timestamp = datetime.now().strftime("%H:%M:%S")
    print(f"[{timestamp}] â„¹ï¸  {message}")

def log_success(message):
    """Logger para Ã©xitos"""
    timestamp = datetime.now().strftime("%H:%M:%S")
    print(f"[{timestamp}] âœ… {message}")

def log_error(message):
    """Logger para errores"""
    timestamp = datetime.now().strftime("%H:%M:%S")
    print(f"[{timestamp}] âŒ {message}")

def scrape_subject_grade(grade, subject, output_prefix="oa_"):
    """Ejecuta scraping para una asignatura y grado especÃ­ficos"""
    
    output_file = f"{output_prefix}{grade.lower()}_{subject.lower()}.csv"
    
    cmd = [
        "python", "scrape_oa.py",
        "--grades", grade,
        "--subjects", subject,
        "--max-oa", "50",  # LÃ­mite generoso
        "--out", output_file,
        "--verbose"
    ]
    
    try:
        log_info(f"ğŸ”„ Procesando {grade}-{subject}...")
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=120)
        
        if result.returncode == 0:
            # Verificar si se creÃ³ el archivo y tiene contenido
            if os.path.exists(output_file):
                df = pd.read_csv(output_file)
                count = len(df)
                if count > 0:
                    log_success(f"âœ… {grade}-{subject}: {count} OA extraÃ­dos")
                    return output_file, count
                else:
                    log_error(f"âŒ {grade}-{subject}: Archivo vacÃ­o")
                    return None, 0
            else:
                log_error(f"âŒ {grade}-{subject}: No se creÃ³ archivo")
                return None, 0
        else:
            log_error(f"âŒ {grade}-{subject}: Error en comando")
            if result.stderr:
                log_error(f"    Error: {result.stderr[:200]}...")
            return None, 0
            
    except subprocess.TimeoutExpired:
        log_error(f"âŒ {grade}-{subject}: Timeout (>120s)")
        return None, 0
    except Exception as e:
        log_error(f"âŒ {grade}-{subject}: ExcepciÃ³n {str(e)}")
        return None, 0

def main():
    """FunciÃ³n principal del scraping completo"""
    
    print("ğŸš€ SCRAPING COMPLETO: INGLÃ‰S + TODAS LAS ASIGNATURAS")
    print("=" * 70)
    
    # MAPEO DE DISPONIBILIDAD DE ASIGNATURAS POR GRADO
    # Basado en curriculumnacional.cl estructura real
    
    subjects_by_grade = {
        '1B': ['MAT', 'LEN', 'CN', 'HIS', 'ING_PROP', 'EDF', 'ART', 'MUS', 'TEC', 'ORI', 'LPO'],
        '2B': ['MAT', 'LEN', 'CN', 'HIS', 'ING_PROP', 'EDF', 'ART', 'MUS', 'TEC', 'ORI', 'LPO'], 
        '3B': ['MAT', 'LEN', 'CN', 'HIS', 'ING_PROP', 'EDF', 'ART', 'MUS', 'TEC', 'ORI', 'LPO'],
        '4B': ['MAT', 'LEN', 'CN', 'HIS', 'ING_PROP', 'EDF', 'ART', 'MUS', 'TEC', 'ORI', 'LPO'],
        '5B': ['MAT', 'LEN', 'CN', 'HIS', 'ING', 'EDF', 'ART', 'MUS', 'TEC', 'ORI', 'LPO'],  # ING (no ING_PROP)
        '6B': ['MAT', 'LEN', 'CN', 'HIS', 'ING', 'EDF', 'ART', 'MUS', 'TEC', 'ORI', 'LPO']   # ING (no ING_PROP)
    }
    
    # Verificar quÃ© ya tenemos para evitar duplicados
    existing_file = "oa_1b_6b_completo_todas_materias.csv"
    processed_combinations = set()
    
    if os.path.exists(existing_file):
        try:
            existing_df = pd.read_csv(existing_file)
            for _, row in existing_df.iterrows():
                combination = f"{row['grade']}-{row['subject']}"
                processed_combinations.add(combination)
            log_info(f"ğŸ“„ Archivo existente encontrado: {len(processed_combinations)} combinaciones ya procesadas")
        except Exception as e:
            log_info(f"âš ï¸  No se pudo leer archivo existente: {e}")
    
    # Contador de progreso
    all_files = []
    total_oa = 0
    stats = {}
    
    # Procesar cada grado y sus asignaturas
    for grade in ['1B', '2B', '3B', '4B', '5B', '6B']:
        grade_files = []
        grade_oa = 0
        
        log_info(f"ğŸ“š Procesando grado {grade}...")
        
        for subject in subjects_by_grade[grade]:
            combination = f"{grade}-{subject}"
            
            # Solo procesar si NO existe o si ya tenemos pocos datos
            if combination not in processed_combinations:
                file_path, count = scrape_subject_grade(grade, subject, f"oa_completo_")
                
                if file_path and count > 0:
                    grade_files.append(file_path)
                    grade_oa += count
                    
                    # EstadÃ­sticas por asignatura
                    if subject not in stats:
                        stats[subject] = 0
                    stats[subject] += count
                
                # PequeÃ±a pausa entre requests
                time.sleep(2)
            else:
                log_info(f"â­ï¸  {combination} ya procesado, saltando...")
        
        all_files.extend(grade_files)
        total_oa += grade_oa
        
        log_success(f"âœ… Grado {grade} completado: {grade_oa} OA en {len(grade_files)} archivos")
    
    # COMBINAR TODOS LOS ARCHIVOS NUEVOS CON LOS EXISTENTES
    log_info("ğŸ”„ Combinando todos los archivos...")
    
    all_dataframes = []
    
    # Cargar archivo existente si existe
    if os.path.exists(existing_file):
        try:
            existing_df = pd.read_csv(existing_file)
            all_dataframes.append(existing_df)
            log_info(f"ğŸ“„ Cargados {len(existing_df)} registros existentes")
        except Exception as e:
            log_error(f"Error cargando archivo existente: {e}")
    
    # Cargar archivos nuevos
    for file_path in all_files:
        if os.path.exists(file_path):
            try:
                df = pd.read_csv(file_path)
                all_dataframes.append(df)
                log_info(f"ğŸ“„ Cargado {file_path}: {len(df)} registros")
            except Exception as e:
                log_error(f"Error cargando {file_path}: {e}")
    
    # Combinar y eliminar duplicados
    if all_dataframes:
        combined_df = pd.concat(all_dataframes, ignore_index=True)
        
        # Eliminar duplicados basado en cÃ³digo OA
        initial_count = len(combined_df)
        combined_df = combined_df.drop_duplicates(subset=['oa_code'], keep='first')
        final_count = len(combined_df)
        
        duplicates_removed = initial_count - final_count
        if duplicates_removed > 0:
            log_info(f"ğŸ”„ Duplicados eliminados: {duplicates_removed}")
        
        # Guardar archivo final
        final_file = "oa_1b_6b_completo_todas_materias_final.csv"
        combined_df.to_csv(final_file, index=False, encoding='utf-8')
        
        log_success(f"ğŸ’¾ Archivo final guardado: {final_file}")
        log_success(f"ğŸ“Š Total registros finales: {final_count}")
        
        # ESTADÃSTICAS FINALES
        print("\nğŸ‰ RESULTADOS FINALES DEL SCRAPING COMPLETO")
        print("=" * 70)
        
        print(f"ğŸ“‹ Total OA extraÃ­dos: {final_count}")
        
        # Por grado
        print(f"\nğŸ“š DISTRIBUCIÃ“N POR GRADO:")
        grade_counts = combined_df['grade'].value_counts().sort_index()
        for grade, count in grade_counts.items():
            percentage = (count / final_count) * 100
            print(f"   {grade}: {count:3d} OA ({percentage:5.1f}%)")
        
        # Por asignatura
        print(f"\nğŸ“– DISTRIBUCIÃ“N POR ASIGNATURA:")
        subject_counts = combined_df['subject'].value_counts().sort_values(ascending=False)
        for subject, count in subject_counts.items():
            percentage = (count / final_count) * 100
            print(f"   {subject}: {count:3d} OA ({percentage:5.1f}%)")
        
        # VerificaciÃ³n InglÃ©s especÃ­fica
        ing_prop_data = combined_df[combined_df['subject'] == 'ING_PROP']
        ing_data = combined_df[combined_df['subject'] == 'ING']
        
        if len(ing_prop_data) > 0 or len(ing_data) > 0:
            print(f"\nğŸ‡¬ğŸ‡§ VERIFICACIÃ“N INGLÃ‰S:")
            if len(ing_prop_data) > 0:
                print(f"   ğŸ“˜ InglÃ©s Propuesta (1Â°-4Â°): {len(ing_prop_data)} OA")
                ing_prop_grades = ing_prop_data['grade'].value_counts().sort_index()
                for grade, count in ing_prop_grades.items():
                    print(f"      {grade}: {count} OA")
            
            if len(ing_data) > 0:
                print(f"   ğŸ“— InglÃ©s (5Â°-6Â°): {len(ing_data)} OA")
                ing_grades = ing_data['grade'].value_counts().sort_index()
                for grade, count in ing_grades.items():
                    print(f"      {grade}: {count} OA")
        
        print(f"\nğŸ¯ PRÃ“XIMOS PASOS:")
        print(f"   1ï¸âƒ£  Enriquecer: python enrich_oa.py --input {final_file}")
        print(f"   2ï¸âƒ£  Generar SQL: python generate_final_1b_6b.py --input {final_file}")
        print(f"   3ï¸âƒ£  Cargar a Supabase: python load_to_supabase_final.py")
        
    else:
        log_error("âŒ No se encontraron archivos para combinar")
    
    # Limpiar archivos temporales (opcional)
    cleanup = input("\nğŸ—‘ï¸  Â¿Eliminar archivos temporales? (s/N): ").lower().strip()
    if cleanup == 's':
        for file_path in all_files:
            if os.path.exists(file_path):
                try:
                    os.remove(file_path)
                    log_info(f"ğŸ—‘ï¸  Eliminado: {file_path}")
                except Exception as e:
                    log_error(f"Error eliminando {file_path}: {e}")

if __name__ == "__main__":
    main() 