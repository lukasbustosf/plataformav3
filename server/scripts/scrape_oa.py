#!/usr/bin/env python3
"""
Script de scraping OA MINEDUC ‚Üí CSV
Implementa el pipeline especificado en MODULO II - Planificaci√≥n EDU21
Actualizado para usar la estructura real del portal curriculumnacional.cl

Uso:
    pip install requests beautifulsoup4 pandas psycopg[binary]
    python scrape_oa.py --year 2023 --out oa_raw.csv --max-oa 100
"""

import requests
import pandas as pd
import argparse
import time
import logging
from bs4 import BeautifulSoup
from urllib.parse import urljoin, urlparse
from datetime import datetime
import re
import sys
import os

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class MinEducOAScraper:
    def __init__(self, year="2023", max_oa_limit=100):
        self.year = year
        self.max_oa_limit = max_oa_limit  # L√≠mite para testing
        self.base_url = "https://www.curriculumnacional.cl"
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        })
        
        # Mapeo de asignaturas basado en URLs reales del sitio
        self.subjects = {
            'MAT': 'matematica',
            'LEN': 'lenguaje-comunicacion',  # Corregido seg√∫n URL real
            'CN': 'ciencias-naturales', 
            'HIS': 'historia-geografia-ciencias-sociales',
            'ING': 'ingles',  # Ingl√©s para 5¬∞-6¬∞ b√°sico
            'ING_PROP': 'ingles-propuesta',  # Ingl√©s (Propuesta) para 1¬∞-4¬∞ b√°sico
            'EDF': 'educacion-fisica-salud',
            'ART': 'artes-visuales',
            'MUS': 'musica',
            'TEC': 'tecnologia',
            'ORI': 'orientacion',
            'LPO': 'lengua-cultura-pueblos-originarios-ancestrales'  # Nueva materia
        }
        
        # Par√°metros adicionales por asignatura
        self.subject_params = {
            'LEN': '?priorizacion=0',  # Lenguaje requiere par√°metro de priorizaci√≥n
            'TEC': '?priorizacion=0',  # Tecnolog√≠a requiere par√°metro
            'ORI': '?priorizacion=0',  # Orientaci√≥n requiere par√°metro
            'MUS': '?priorizacion=0',  # M√∫sica requiere par√°metro
            'LPO': '?priorizacion=0',  # Lengua Pueblos Originarios requiere par√°metro
            'ING': '?priorizacion=0',  # Ingl√©s (5¬∞-6¬∞ b√°sico) requiere par√°metro
            'ING_PROP': '?priorizacion=0',  # Ingl√©s Propuesta (1¬∞-4¬∞ b√°sico) requiere par√°metro
            'HIS': '?priorizacion=0',  # Historia requiere par√°metro
            'EDF': '?priorizacion=0',  # Educaci√≥n F√≠sica requiere par√°metro
            'CN': '?priorizacion=0',   # Ciencias Naturales requiere par√°metro
            'ART': '?priorizacion=0',  # Artes Visuales requiere par√°metro
            'MAT': '',  # Matem√°tica no requiere par√°metros adicionales
        }
        
        # Mapeo de grados a ciclos y nombres de URL
        self.grade_cycles = {
            '1B': ('1o-6o-basico', '1-basico'),
            '2B': ('1o-6o-basico', '2-basico'),
            '3B': ('1o-6o-basico', '3-basico'),
            '4B': ('1o-6o-basico', '4-basico'),
            '5B': ('1o-6o-basico', '5-basico'),
            '6B': ('1o-6o-basico', '6-basico'),
            '7B': ('7o-basico-2o-medio', '7-basico'),
            '8B': ('7o-basico-2o-medio', '8-basico'),
            '1M': ('7o-basico-2o-medio', '1-medio'),
            '2M': ('7o-basico-2o-medio', '2-medio'),
            '3M': ('3o-4o-medio', '3-medio'),
            '4M': ('3o-4o-medio', '4-medio'),
        }
        
        # Patrones de c√≥digos OA por asignatura (actualizados para 1¬∞-6¬∞ b√°sico)
        self.oa_patterns = {
            'MAT': [
                r'MA01OA\d+',  # MA01OA01, MA01OA02, etc.
                r'MA02OA\d+',  # MA02OA01, MA02OA02, etc.
                r'MA03OA\d+',  # MA03OA01, MA03OA02, etc.
                r'MA04OA\d+',  # MA04OA01, MA04OA02, etc.
                r'MA05OA\d+',  # MA05OA01, MA05OA02, etc.
                r'MA06OA\d+'   # MA06OA01, MA06OA02, etc.
            ],
            'LEN': [
                r'LE01OA\d+',  # LE01OA01, LE01OA02, etc.
                r'LE02OA\d+',  # LE02OA01, LE02OA02, etc.
                r'LE03OA\d+',  # LE03OA01, LE03OA02, etc.
                r'LE04OA\d+',  # LE04OA01, LE04OA02, etc.
                r'LE05OA\d+',  # LE05OA01, LE05OA02, etc.
                r'LE06OA\d+'   # LE06OA01, LE06OA02, etc.
            ],
            'CN': [
                r'CN01OA\d+',  # CN01OA01, CN01OA02, etc.
                r'CN02OA\d+',  # CN02OA01, CN02OA02, etc.
                r'CN03OA\d+',  # CN03OA01, CN03OA02, etc.
                r'CN04OA\d+',  # CN04OA01, CN04OA02, etc.
                r'CN05OA\d+',  # CN05OA01, CN05OA02, etc.
                r'CN06OA\d+'   # CN06OA01, CN06OA02, etc.
            ],
            'HIS': [
                r'HI01OA\d+',  # HI01OA01, HI01OA02, etc.
                r'HI02OA\d+',  # HI02OA01, HI02OA02, etc.
                r'HI03OA\d+',  # HI03OA01, HI03OA02, etc.
                r'HI04OA\d+',  # HI04OA01, HI04OA02, etc.
                r'HI05OA\d+',  # HI05OA01, HI05OA02, etc.
                r'HI06OA\d+'   # HI06OA01, HI06OA02, etc.
            ],
            'ING': [
                r'IN01OA\d+',  # IN01OA01, IN01OA02, etc.
                r'IN02OA\d+',  # IN02OA01, IN02OA02, etc.
                r'IN03OA\d+',  # IN03OA01, IN03OA02, etc.
                r'IN04OA\d+',  # IN04OA01, IN04OA02, etc.
                r'IN05OA\d+',  # IN05OA01, IN05OA02, etc.
                r'IN06OA\d+'   # IN06OA01, IN06OA02, etc.
            ],
            'ING_PROP': [
                r'EN01OA\d+',  # EN01OA01, EN01OA02, etc. (Ingl√©s Propuesta 1¬∞-4¬∞)
                r'EN02OA\d+',  # EN02OA01, EN02OA02, etc.
                r'EN03OA\d+',  # EN03OA01, EN03OA02, etc.
                r'EN04OA\d+'   # EN04OA01, EN04OA02, etc.
            ],
            'EDF': [
                r'EF01OA\d+',  # EF01OA01, EF01OA02, etc.
                r'EF02OA\d+',  # EF02OA01, EF02OA02, etc.
                r'EF03OA\d+',  # EF03OA01, EF03OA02, etc.
                r'EF04OA\d+',  # EF04OA01, EF04OA02, etc.
                r'EF05OA\d+',  # EF05OA01, EF05OA02, etc.
                r'EF06OA\d+'   # EF06OA01, EF06OA02, etc.
            ],
            'ART': [
                r'AR01OA\d+',  # AR01OA01, AR01OA02, etc.
                r'AR02OA\d+',  # AR02OA01, AR02OA02, etc.
                r'AR03OA\d+',  # AR03OA01, AR03OA02, etc.
                r'AR04OA\d+',  # AR04OA01, AR04OA02, etc.
                r'AR05OA\d+',  # AR05OA01, AR05OA02, etc.
                r'AR06OA\d+'   # AR06OA01, AR06OA02, etc.
            ],
            'MUS': [
                r'MU01OA\d+',  # MU01OA01, MU01OA02, etc.
                r'MU02OA\d+',  # MU02OA01, MU02OA02, etc.
                r'MU03OA\d+',  # MU03OA01, MU03OA02, etc.
                r'MU04OA\d+',  # MU04OA01, MU04OA02, etc.
                r'MU05OA\d+',  # MU05OA01, MU05OA02, etc.
                r'MU06OA\d+'   # MU06OA01, MU06OA02, etc.
            ],
            'TEC': [
                r'TE01OA\d+',  # TE01OA01, TE01OA02, etc.
                r'TE02OA\d+',  # TE02OA01, TE02OA02, etc.
                r'TE03OA\d+',  # TE03OA01, TE03OA02, etc.
                r'TE04OA\d+',  # TE04OA01, TE04OA02, etc.
                r'TE05OA\d+',  # TE05OA01, TE05OA02, etc.
                r'TE06OA\d+'   # TE06OA01, TE06OA02, etc.
            ],
            'ORI': [
                r'OR01OA\d+',  # OR01OA01, OR01OA02, etc.
                r'OR02OA\d+',  # OR02OA01, OR02OA02, etc.
                r'OR03OA\d+',  # OR03OA01, OR03OA02, etc.
                r'OR04OA\d+',  # OR04OA01, OR04OA02, etc.
                r'OR05OA\d+',  # OR05OA01, OR05OA02, etc.
                r'OR06OA\d+'   # OR06OA01, OR06OA02, etc.
            ],
            'LPO': [
                r'LP01OA\d+',  # LP01OA01, LP01OA02, etc.
                r'LP02OA\d+',  # LP02OA01, LP02OA02, etc.
                r'LP03OA\d+',  # LP03OA01, LP03OA02, etc.
                r'LP04OA\d+',  # LP04OA01, LP04OA02, etc.
                r'LP05OA\d+',  # LP05OA01, LP05OA02, etc.
                r'LP06OA\d+'   # LP06OA01, LP06OA02, etc.
            ]
        }
        
        self.oa_data = []
        
    def build_url(self, grade, subject):
        """
        Construye la URL espec√≠fica para scraping seg√∫n grado y asignatura
        Basado en la estructura real del sitio curriculumnacional.cl
        """
        cycle_info = self.grade_cycles.get(grade)
        subject_name = self.subjects.get(subject)
        
        if not cycle_info or not subject_name:
            logger.warning(f"Grado {grade} o asignatura {subject} no v√°lidos")
            return None
            
        cycle, grade_name = cycle_info
        
        # URL basada en estructura real: /curriculum/{ciclo}/{asignatura}/{grado}
        url = f"{self.base_url}/curriculum/{cycle}/{subject_name}/{grade_name}"
        
        # A√±adir par√°metros adicionales si los requiere la asignatura
        extra_params = self.subject_params.get(subject, '')
        if extra_params:
            url += extra_params
            
        logger.info(f"üîó URL construida para {grade}-{subject}: {url}")
        return url
    
    def find_oa_description(self, item, soup):
        """
        Busca la descripci√≥n del OA asociada al elemento encontrado
        """
        description = ""
        
        try:
            # Si el item es un elemento HTML
            if hasattr(item, 'find_next'):
                # Buscar siguiente p√°rrafo
                next_p = item.find_next('p')
                if next_p:
                    description = next_p.get_text(strip=True)
                
                # Si no hay p√°rrafo, buscar siguiente div
                if not description:
                    next_div = item.find_next('div')
                    if next_div:
                        description = next_div.get_text(strip=True)
            
            # Si el item es texto, buscar en el contexto
            else:
                # Buscar el elemento padre que contiene este texto
                parent = soup.find(string=item)
                if parent and hasattr(parent, 'parent'):
                    # Buscar siguiente elemento con texto
                    siblings = parent.parent.find_next_siblings()
                    for sibling in siblings[:3]:  # Revisar hasta 3 elementos siguientes
                        text = sibling.get_text(strip=True)
                        if len(text) > 20:  # Descripci√≥n m√≠nima
                            description = text
                            break
            
        except Exception as e:
            logger.debug(f"Error buscando descripci√≥n: {e}")
        
        return description
    
    def alternative_extraction_method(self, soup, grade, subject, url):
        """
        M√©todo alternativo de extracci√≥n para casos donde el m√©todo principal no funciona
        """
        oa_data = []
        
        try:
            # Buscar todos los elementos h4 que podr√≠an contener OA
            h4_elements = soup.find_all('h4')
            
            logger.info(f"üîÑ M√©todo alternativo: encontrados {len(h4_elements)} elementos h4")
            
            for i, h4 in enumerate(h4_elements[:self.max_oa_limit]):
                text = h4.get_text(strip=True)
                
                # Buscar patrones de OA en el texto usando patrones din√°micos
                oa_pattern = None
                
                # Usar todos los patrones disponibles
                for subj_code, patterns in self.oa_patterns.items():
                    for pattern in patterns:
                        # Convertir patr√≥n regex a b√∫squeda con espacios opcionales
                        search_pattern = pattern.replace('OA\\d+', r'\s*OA\s*\d{2}')
                        match = re.search(search_pattern, text, re.IGNORECASE)
                        if match:
                            oa_pattern = match
                            break
                    if oa_pattern:
                        break
                
                if oa_pattern:
                    oa_code = oa_pattern.group(0).replace(' ', '')
                    
                    # Buscar descripci√≥n en el siguiente elemento
                    description = self.find_oa_description(h4, soup)
                    
                    if description and len(description) > 20:
                        oa_data.append({
                            'oa_code': oa_code,
                            'oa_desc': description,
                            'grade': grade,
                            'subject': subject,
                            'source_url': url,
                            'scraped_at': datetime.now().isoformat()
                        })
                        
                        logger.info(f"üéØ OA alternativo encontrado: {oa_code}")
                        logger.debug(f"   üìù Descripci√≥n: {description[:80]}...")
                
                # Si no encuentra patr√≥n espec√≠fico, buscar contenido que parezca OA
                elif (len(text) > 50 and 
                      any(verb in text.lower() for verb in ['demostrar', 'comprender', 'aplicar', 'analizar', 'identificar', 'resolver', 'explicar', 'describir'])):
                    
                    # Generar c√≥digo OA basado en posici√≥n
                    oa_code = f"{subject}{grade[-1]}{grade[0]}OA{str(i+1).zfill(2)}"
                    
                    oa_data.append({
                        'oa_code': oa_code,
                        'oa_desc': text,
                        'grade': grade,
                        'subject': subject,
                        'source_url': url,
                        'scraped_at': datetime.now().isoformat()
                    })
                    
                    logger.info(f"üîÑ OA inferido: {oa_code}")
                    logger.debug(f"   üìù Texto: {text[:80]}...")
                    
                    if len(oa_data) >= 5:  # Limitar extracci√≥n alternativa
                        break
        
        except Exception as e:
            logger.warning(f"Error en m√©todo alternativo: {e}")
        
        return oa_data
    
    def extract_oa_mineduc_structure(self, soup, grade, subject, url):
        """
        Extracci√≥n espec√≠fica para la estructura real del portal curriculumnacional.cl
        Basado en el patr√≥n: h4 > "Objetivo de aprendizaje LE01 OA 01" seguido por descripci√≥n
        """
        oa_data = []
        
        try:
            # Buscar todos los h4 que contengan "Objetivo de aprendizaje"
            objective_headers = soup.find_all('h4', string=re.compile(r'Objetivo de aprendizaje.*', re.IGNORECASE))
            
            logger.info(f"üéØ M√©todo estructura MINEDUC: encontrados {len(objective_headers)} objetivos")
            
            for header in objective_headers[:self.max_oa_limit]:
                try:
                    header_text = header.get_text(strip=True)
                    logger.debug(f"üìã Procesando header: {header_text}")
                    
                    # Extraer c√≥digo OA del header
                    # Patrones din√°micos basados en self.oa_patterns para todas las asignaturas
                    oa_match = None
                    
                    # Buscar patr√≥n de OA usando todos los patrones disponibles
                    for subj_code, patterns in self.oa_patterns.items():
                        for pattern in patterns:
                            # Convertir patr√≥n regex a b√∫squeda en texto con espacios
                            # TE01OA\d+ -> TE01 OA \d+
                            search_pattern = pattern.replace('OA\\d+', r'OA\s+\d{2}')
                            match = re.search(search_pattern, header_text, re.IGNORECASE)
                            if match:
                                oa_match = match
                                break
                        if oa_match:
                            break
                    
                    if oa_match:
                        oa_code = oa_match.group(0).replace(' ', '')
                        logger.debug(f"‚úÖ C√≥digo OA encontrado: {oa_code}")
                        
                        # Buscar la descripci√≥n - puede estar en el siguiente elemento
                        description = ""
                        
                        # M√©todo 1: Buscar en el texto restante del header despu√©s del c√≥digo
                        remaining_text = header_text[oa_match.end():].strip()
                        if len(remaining_text) > 20:
                            description = remaining_text
                            
                        # M√©todo 2: Buscar en el siguiente elemento sibling
                        if not description:
                            next_sibling = header.find_next_sibling()
                            if next_sibling:
                                desc_text = next_sibling.get_text(strip=True)
                                if len(desc_text) > 20:
                                    description = desc_text
                        
                        # M√©todo 3: Buscar en el siguiente p o div
                        if not description:
                            next_p = header.find_next('p')
                            if next_p:
                                desc_text = next_p.get_text(strip=True)
                                if len(desc_text) > 20:
                                    description = desc_text
                        
                        if description:
                            oa_data.append({
                                'oa_code': oa_code,
                                'oa_desc': description,
                                'grade': grade,
                                'subject': subject,
                                'source_url': url,
                                'scraped_at': datetime.now().isoformat()
                            })
                            
                            logger.info(f"‚úÖ OA extra√≠do: {oa_code}")
                            logger.debug(f"   üìù Descripci√≥n: {description[:80]}...")
                        else:
                            logger.warning(f"‚ö†Ô∏è  No se encontr√≥ descripci√≥n para {oa_code}")
                            
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è  Error procesando header OA: {e}")
                    continue
                    
        except Exception as e:
            logger.warning(f"Error en m√©todo estructura MINEDUC: {e}")
        
        return oa_data
    
    def extract_oa_from_page(self, url, grade, subject):
        """
        Extrae OA desde una p√°gina espec√≠fica del portal MINEDUC
        Parseando la estructura HTML real del sitio
        """
        try:
            logger.info(f"üîç Extrayendo OA de {grade}-{subject}: {url}")
            
            response = self.session.get(url, timeout=15)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            oa_data = []
            
            # M√âTODO 0: Estructura espec√≠fica MINEDUC (nuevo - m√°s preciso)
            logger.info("üéØ Intentando m√©todo estructura espec√≠fica MINEDUC...")
            oa_data = self.extract_oa_mineduc_structure(soup, grade, subject, url)
            
            # Si no encontramos nada, continuar con m√©todos alternativos
            if not oa_data:
                # M√âTODO 1: Buscar por ID espec√≠fico (basado en el HTML real)
                # Buscar elementos que contengan c√≥digos de OA como MA01 OA 01
                oa_elements = soup.find_all('h4', id=re.compile(r'objetivo.*oa.*', re.IGNORECASE))
                
                if not oa_elements:
                    # M√âTODO 2: Buscar por texto que contiene c√≥digos de OA
                    oa_elements = soup.find_all(string=re.compile(r'(MA|LE|CN|HIS|ING|EDF|ART|MUS|TEC|ORI|TE|OR|MU|LPO)\d{2}\s+OA\s+\d{2}', re.IGNORECASE))
                
                if not oa_elements:
                    # M√âTODO 3: Buscar elementos h4 que contengan "Objetivo de aprendizaje"
                    oa_elements = soup.find_all('h4', string=re.compile(r'Objetivo de aprendizaje', re.IGNORECASE))
                
                logger.info(f"üìã Encontrados {len(oa_elements)} elementos potenciales de OA")
                
                # Procesar elementos encontrados con m√©todos alternativos
                for item in oa_elements[:self.max_oa_limit]:  # Limitar para testing
                    try:
                        if hasattr(item, 'get_text'):
                            text = item.get_text(strip=True)
                        else:
                            text = str(item).strip()
                        
                        # Extraer c√≥digo OA
                        oa_code_match = re.search(r'([A-Z]{2,3}\d{2}\s+OA\s+\d{2})', text, re.IGNORECASE)
                        if oa_code_match:
                            oa_code = oa_code_match.group(1).replace(' ', '')
                            
                            # Buscar descripci√≥n
                            description = self.find_oa_description(item, soup)
                            
                            if description and len(description) > 10:  # Validar que hay descripci√≥n
                                oa_data.append({
                                    'oa_code': oa_code,
                                    'oa_desc': description,
                                    'grade': grade,
                                    'subject': subject,
                                    'source_url': url,
                                    'scraped_at': datetime.now().isoformat()
                                })
                                
                                logger.info(f"‚úÖ OA extra√≠do: {oa_code}")
                                logger.debug(f"   üìù Descripci√≥n: {description[:100]}...")
                    
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è  Error procesando item OA: {e}")
                        continue
                
                # Si a√∫n no encontramos nada, intentar m√©todo alternativo final
                if not oa_data:
                    logger.info("üîÑ Intentando m√©todo alternativo de extracci√≥n...")
                    oa_data = self.alternative_extraction_method(soup, grade, subject, url)
            
            else:
                logger.info(f"‚úÖ M√©todo estructura MINEDUC exitoso: {len(oa_data)} OA encontrados")
            
            logger.info(f"üìä Total extra√≠dos: {len(oa_data)} OA de {grade}-{subject}")
            return oa_data
            
        except requests.exceptions.RequestException as e:
            logger.error(f"‚ùå Error al acceder {url}: {e}")
            return []
        except Exception as e:
            logger.error(f"üí• Error inesperado procesando {url}: {e}")
            return []
    
    def scrape_all_oa(self, grades=None, subjects=None):
        """
        Scraping principal de todos los OA seg√∫n filtros especificados
        CON L√çMITE PARA TESTING
        """
        all_oa_data = []
        
        # Usar todos los grados y asignaturas si no se especifican
        target_grades = grades or ['1B']  # Solo 1¬∞ B√°sico para testing
        target_subjects = subjects or ['MAT', 'LEN', 'CN', 'HIS', 'ING', 'EDF', 'ART', 'MUS', 'TEC', 'ORI']  # Todas las materias 1B (excluyendo LPO por ser opcional)
        
        logger.info(f"üöÄ Iniciando scraping LIMITADO para testing:")
        logger.info(f"   üìö Grados: {target_grades}")
        logger.info(f"   üìñ Asignaturas: {target_subjects}")
        logger.info(f"   üî¢ M√°ximo OA por p√°gina: {self.max_oa_limit}")
        
        total_combinations = len(target_grades) * len(target_subjects)
        processed = 0
        
        for grade in target_grades:
            for subject in target_subjects:
                processed += 1
                
                logger.info(f"üìà Progreso: {processed}/{total_combinations} - Procesando {grade}-{subject}")
                
                url = self.build_url(grade, subject)
                if url:
                    oa_data = self.extract_oa_from_page(url, grade, subject)
                    all_oa_data.extend(oa_data)
                    
                    # Mostrar muestra de lo extra√≠do
                    if oa_data:
                        logger.info(f"‚úÖ Muestra extra√≠da de {grade}-{subject}:")
                        for oa in oa_data[:2]:  # Mostrar solo primeros 2
                            logger.info(f"   üéØ {oa['oa_code']}: {oa['oa_desc'][:80]}...")
                    
                    # Delay entre requests para ser respetuoso
                    time.sleep(1)
                    
                    # L√≠mite total para testing
                    if len(all_oa_data) >= self.max_oa_limit:
                        logger.info(f"üõë L√≠mite de testing alcanzado: {self.max_oa_limit} OA")
                        break
                else:
                    logger.warning(f"‚ö†Ô∏è  No se pudo construir URL para {grade}-{subject}")
            
            if len(all_oa_data) >= self.max_oa_limit:
                break
        
        # Eliminar duplicados manteniendo el primer registro
        unique_oa_data = []
        seen_codes = set()
        
        for oa in all_oa_data:
            if oa['oa_code'] not in seen_codes:
                unique_oa_data.append(oa)
                seen_codes.add(oa['oa_code'])
        
        logger.info(f"üéâ Scraping completado: {len(all_oa_data)} OA extra√≠dos ({len(unique_oa_data)} √∫nicos)")
        
        # Mostrar resumen detallado
        if unique_oa_data:
            subjects_found = set(oa['subject'] for oa in unique_oa_data)
            grades_found = set(oa['grade'] for oa in unique_oa_data)
            logger.info(f"üìä Resumen extra√≠do:")
            logger.info(f"   üìö Asignaturas encontradas: {list(subjects_found)}")
            logger.info(f"   üéì Grados encontrados: {list(grades_found)}")
        
        return unique_oa_data
    
    def save_to_csv(self, oa_data, output_file):
        """
        Guarda los OA extra√≠dos a CSV con las columnas especificadas
        """
        if not oa_data:
            logger.error("No hay datos de OA para guardar")
            return False
        
        try:
            # Crear DataFrame con las columnas especificadas
            df = pd.DataFrame(oa_data)
            
            # Reordenar columnas seg√∫n especificaci√≥n
            df = df[['oa_code', 'oa_desc', 'grade', 'subject', 'source_url', 'scraped_at']]
            
            # Guardar CSV con encoding UTF-8
            df.to_csv(output_file, index=False, encoding='utf-8')
            
            logger.info(f"üìÑ Archivo CSV guardado: {output_file}")
            logger.info(f"üìä Registros guardados: {len(df)}")
            
            return True
            
        except Exception as e:
            logger.error(f"Error al guardar CSV: {e}")
            return False

    def extract_oa_from_text(self, text, subject, grade):
        """
        Extrae c√≥digos de OA del texto HTML usando patrones espec√≠ficos por asignatura
        """
        oa_codes = set()
        
        # Usar patrones espec√≠ficos para la asignatura actual
        if subject in self.oa_patterns:
            for pattern in self.oa_patterns[subject]:
                matches = re.findall(pattern, text, re.IGNORECASE)
                oa_codes.update(matches)
        
        return list(oa_codes)

def main():
    parser = argparse.ArgumentParser(description='Scraper de OA desde portal MINEDUC - Versi√≥n Testing')
    parser.add_argument('--year', default='2023', help='A√±o de la malla curricular')
    parser.add_argument('--out', default='oa_raw.csv', help='Archivo CSV de salida')
    parser.add_argument('--grades', nargs='+', help='Grados espec√≠ficos (ej: 1B 2B 7B)')
    parser.add_argument('--subjects', nargs='+', help='Asignaturas espec√≠ficas (ej: MAT LEN)')
    parser.add_argument('--max-oa', type=int, default=100, help='M√°ximo OA para testing (default: 100)')
    parser.add_argument('--verbose', '-v', action='store_true', help='Logging detallado')
    parser.add_argument('--full-scrape', action='store_true', help='Scraping completo (desactivar l√≠mites)')
    
    args = parser.parse_args()
    
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    # Determinar l√≠mite de OA
    max_limit = None if args.full_scrape else args.max_oa
    
    # Inicializar scraper
    scraper = MinEducOAScraper(year=args.year, max_oa_limit=max_limit)
    
    logger.info("üéØ SCRAPER OA MINEDUC - VERSI√ìN TESTING")
    logger.info(f"üî¢ L√≠mite OA: {max_limit if max_limit else 'SIN L√çMITE'}")
    logger.info(f"üìÖ A√±o: {args.year}")
    
    try:
        # Ejecutar scraping
        oa_data = scraper.scrape_all_oa(grades=args.grades, subjects=args.subjects)
        
        if oa_data:
            # Guardar en CSV
            success = scraper.save_to_csv(oa_data, args.out)
            
            if success:
                logger.info("üéâ ¬°SCRAPING COMPLETADO EXITOSAMENTE!")
                logger.info(f"üìÑ Archivo generado: {args.out}")
                logger.info(f"üìä Total OA extra√≠dos: {len(oa_data)}")
                logger.info(f"üîÑ Siguiente paso: python enrich_oa.py --input {args.out}")
                
                # Mostrar muestra del contenido
                logger.info("üìã MUESTRA DEL CONTENIDO EXTRA√çDO:")
                for i, oa in enumerate(oa_data[:3]):
                    logger.info(f"   {i+1}. {oa['oa_code']}")
                    logger.info(f"      üìù {oa['oa_desc'][:100]}...")
                    logger.info(f"      üéì Grado: {oa['grade']} | üìö Asignatura: {oa['subject']}")
                
                sys.exit(0)
            else:
                logger.error("‚ùå Error al guardar CSV")
                sys.exit(1)
        else:
            logger.error("‚ùå No se pudieron extraer OA")
            logger.info("üí° POSIBLES CAUSAS:")
            logger.info("   ‚Ä¢ Cambios en la estructura del sitio MINEDUC")
            logger.info("   ‚Ä¢ Problemas de conectividad")
            logger.info("   ‚Ä¢ URLs incorrectas")
            logger.info("üîß SOLUCIONES:")
            logger.info("   ‚Ä¢ Verificar URLs manualmente en el navegador")
            logger.info("   ‚Ä¢ Ejecutar con --verbose para m√°s detalles") 
            logger.info("   ‚Ä¢ Probar con grados/asignaturas espec√≠ficos")
            sys.exit(1)
            
    except KeyboardInterrupt:
        logger.info("‚èπÔ∏è  Scraping interrumpido por el usuario")
        sys.exit(1)
    except Exception as e:
        logger.error(f"üí• Error inesperado: {e}")
        logger.error("üîß Ejecuta con --verbose para m√°s informaci√≥n")
        sys.exit(1)

if __name__ == "__main__":
    main() 